{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkGDb5e6768h"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install kaggle pyspark pyarrow"
      ],
      "metadata": {
        "id": "M5nUhXSK9EuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "a79IR25A9UbI",
        "outputId": "7fa4afb6-4f9f-462a-a670-47a1370bba4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb42c3a8-8f9d-4c1d-8c65-799b93afb454\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb42c3a8-8f9d-4c1d-8c65-799b93afb454\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tokens.ts to tokens.ts\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens.ts': b'tokens\\nKGAT_1943f2f81f04e39172723dd31c2ac3c0\\n\\nexport KAGGLE_API_TOKEN=KGAT_1943f2f81f04e39172723dd31c2ac3c0\\n\\nkaggle competitions list'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "9_Uznr0G9qlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1299785e-048d-4c20-ee43-c6b5620c81e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWGlt6yG9zfe",
        "outputId": "3afb7852-c714-46c7-e2a8-b41b68814cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                     size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  --------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "saidaminsaidaxmadov/chocolate-sales                             Chocolate Sales                                         468320  2026-01-04 14:23:35.490000          12469        211  1.0              \n",
            "sonalshinde123/work-from-home-employee-burnout-dataset          Work From Home Employee Burnout Dataset                  27962  2026-01-31 03:28:22.227000            793         31  1.0              \n",
            "rockyt07/social-media-user-analysis                             Social Media User Analysis                           247842357  2026-01-14 02:28:41.970000           7338        149  1.0              \n",
            "vishardmehta/indian-engineering-college-placement-dataset       Indian Engineering College Placement Dataset            137603  2026-01-24 15:23:40.150000           2052         53  1.0              \n",
            "ibrahimshahrukh/european-housing-price-index-dataset            European Housing Price Index 2022-2025 | Quarterly        6390  2026-01-29 03:38:44.913000            562         24  1.0              \n",
            "devgondaliya007/smartphone-specifications-dataset               Smartphone Specifications Dataset                        26292  2026-01-29 03:51:41.243000           1017         39  0.9411765        \n",
            "neurocipher/heartdisease                                        Heart Disease                                             3491  2025-12-11 15:29:14.327000          20055        445  1.0              \n",
            "aliiihussain/amazon-sales-dataset                               Amazon_Sales_Dataset                                   1297759  2026-02-01 11:37:12.353000           1076         29  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = \"mohamedbakhet/amazon-books-reviews\"\n",
        "\n",
        "!mkdir -p /content/data\n",
        "!kaggle datasets download -d {DATASET} -p /content/data --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1EfiHyY97Zp",
        "outputId": "696101a2-396e-461a-fc1b-ae72823f7b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content/data\n",
            "100% 1.06G/1.06G [00:03<00:00, 250MB/s]\n",
            "100% 1.06G/1.06G [00:03<00:00, 302MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS1G_QEf-QKp",
        "outputId": "f45d5585-c83f-48ba-8634-983a0b20491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.9G\n",
            "drwxr-xr-x 2 root root 4.0K Feb  3 20:35 .\n",
            "drwxr-xr-x 1 root root 4.0K Feb  3 20:34 ..\n",
            "-rw-r--r-- 1 root root 173M Feb  3 20:35 books_data.csv\n",
            "-rw-r--r-- 1 root root 2.7G Feb  3 20:35 Books_rating.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/data\"\n",
        "RATINGS_CSV = f\"{DATA_DIR}/Books_rating.csv\"\n",
        "BOOKS_CSV = f\"{DATA_DIR}/books_data.csv\"\n",
        "\n",
        "# just to save runtime\n",
        "USE_FULL_DATA = False\n",
        "SAMPLE_FRAC = 0.20\n",
        "SEED = 12345\n"
      ],
      "metadata": {
        "id": "H9DNtTwk_rei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K_EVAL = 10 # report size\n",
        "MAX_USERS_EVAL = 2000 # cap for speed\n",
        "MIN_TEST_POS = 1 # user must have at least this many test items\n",
        "MIN_TRAIN_ITEMS = 3 # need some history to recommend\n"
      ],
      "metadata": {
        "id": "_EllG_ckxl_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the SPark session\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"amd-recsys-books\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n"
      ],
      "metadata": {
        "id": "gfGvhrzgAMNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load book ratings into Spark:\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "ratings = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .csv(RATINGS_CSV)\n",
        ")\n",
        "\n",
        "ratings.printSchema()\n",
        "ratings.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JGTVfxuAdk8",
        "outputId": "d534db09-fb35-4276-c2a2-1da0dd55e180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Price: string (nullable = true)\n",
            " |-- User_id: string (nullable = true)\n",
            " |-- profileName: string (nullable = true)\n",
            " |-- review/helpfulness: string (nullable = true)\n",
            " |-- review/score: string (nullable = true)\n",
            " |-- review/time: string (nullable = true)\n",
            " |-- review/summary: string (nullable = true)\n",
            " |-- review/text: string (nullable = true)\n",
            "\n",
            "+----------+------------------------------+-----+--------------+--------------------------------------+------------------+------------+-----------+-----------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Id        |Title                         |Price|User_id       |profileName                           |review/helpfulness|review/score|review/time|review/summary                                 |review/text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "+----------+------------------------------+-----+--------------+--------------------------------------+------------------+------------+-----------+-----------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1882931173|Its Only Art If Its Well Hung!|NULL |AVCGYZL8FQQTD |\"Jim of Oz \"\"jim-of-oz\"\"\"             |7/7               |4.0         |940636800  |Nice collection of Julie Strain images         |This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with a nice section of paintings by Olivia.If you're looking for heavy literary content, this isn't the place to find it -- there's only about 2 pages with text and everything else is photos.Bottom line: if you only want one book, the Six Foot One ... is probably a better choice, however, if you like Julie like I like Julie, you won't go wrong on this one either.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|0826414346|Dr. Seuss: American Icon      |NULL |A30TK6U7DNS82R|Kevin Killian                         |10/10             |5.0         |1095724800 |Really Enjoyed It                              |I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a good testimonial to the power of Rel's writing and thinking. Rel plays Dr. Seuss the ultimate compliment of treating him as a serious poet as well as one of the 20th century's most interesting visual artists, and after reading his book I decided that a trip to the Mandeville Collections of the library at University of California in San Diego was in order, so I could visit some of the incredible Seuss/Geisel holdings they have there.There's almost too much to take in, for, like William Butler Yeats, Seuss led a career that constantly shifted and metamoprhized itself to meet new historical and political cirsumstances, so he seems to have been both a leftist and a conservative at different junctures of his career, both in politics and in art. As Nel shows us, he was once a cartoonist for the fabled PM magazine and, like Andy Warhol, he served his time slaving in the ad business too. All was in the service of amusing and broadening the minds of US children. Nel doesn't hesitate to administer a sound spanking to the Seuss industry that, since his death, has seen fit to license all kinds of awful products including the recent CAT IN THE HAT film with Mike Myers. Oh, what a cat-astrophe!The book is great and I can especially recommend the work of the picture editor who has given us a bounty of good illustrations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|0826414346|Dr. Seuss: American Icon      |NULL |A3UH4UZ4RSVO82|John Granger                          |10/11             |5.0         |1078790400 |Essential for every personal and Public Library|\"If people become the books they read and if \"\"the child is father to the man                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|0826414346|Dr. Seuss: American Icon      |NULL |A2MVUWT453QH61|\"Roy E. Perry \"\"amateur philosopher\"\"\"|7/7               |4.0         |1090713600 |Phlip Nel gives silly Seuss a serious treatment|Theodore Seuss Geisel (1904-1991), aka &quot;Dr. Seuss,&quot; was one of the most influential writers and artists of the 20th century.In 1959, Rudolf Flesch wrote, &quot;A hundred years from now, children and their parents will still eagerly read the books of a fellow called Ted Geisel, popularly known as Dr. Seuss.&quot;Flesch was too conservative in his prediction. A century, and more, from today, Dr. Seuss will still be read when many authors on today's bestseller lists will be forgotten.Published on the centenary of Geisel's birth, Dr. Seuss: American Icon analyzes six key aspects of Seuss's career: poetry, politics, art, biography, marketing, and influence.In six insightful chapters, Philip Nel, Assistant Professor of English at Kansas State University, discusses &quot;U.S. Laureate of Nonsense,&quot; &quot;Dr. Seuss vs. Adolf Hitler,&quot; &quot;The Doc in the Smock,&quot; &quot;The 5,000 Fingers of Dr. S.,&quot; &quot;The Disneyfication of Dr. Seuss,&quot; and &quot;The Cat in the Hat for President.&quot;Nel gives short shrift to Geisel's childhood and family background--and, indeed, to biography in general--preferring to focus on Seuss's writing and art, from his first book, And to Think That I Saw It on Mulberry Street (1937) to his last book, Oh, the Places You'll Go! (1990).Dr. Seuss's breakthrough year was 1957, when he published the two books with which he is most often identified: The Cat in the Hat and How the Grinch Stole Christmas!Other classic works in the Seussian canon are: Horton Hears a Who! (&quot;A person's a person, no matter how small&quot;), Yertle the Turtle (modeled on the rise of Adolf Hitler), Green Eggs and Ham (Seuss's bestselling book), The Sneeches (a criticism of anti-Semitism), The Lorax (a protest against corporate abuse of the environment), and The Butter Battle Book (a critique of Reagan's enthusiasm for the nuclear arms trace).His favorite work, among the books he authored, was The Cat in the Hat, for it, more than any other, taught children to read.While many of his books have a clear and powerful moral, Seuss had a horror of heavy-handed preaching. He sought to teach and ignite the imagination, but was a lifelong opponent of smug, self-righteous bourgeois moralism.&quot;Seuss was a contrarian,&quot; writes Nel, &quot;who enjoyed challenging people to reconsider their assumptions. [He had a] rebellious imagination and a dispositional distaste for rules and regulations.&quot; His work was a &quot;rational insanity&quot; that exhibited &quot;joyous anarchy&quot; and a &quot;lifelong thrill in misbehaving.&quot;A better subtitle for Nel's work would have been American Icon and Iconoclast.Nel tells of Seuss's early years as an advertising artist and as a agitprop cartoonist. The book, however, is not a biography; it is a serious study in the genres of literary and art criticism.For readers who want more biographical information, Nel recommends Dr. Seuss and Mr. Geisel, by Judith Morgan and Neil Morgan (1995), which he describes as &quot;the definitive biography and the single best secondary source on Seuss. Any discussion of Seuss's life and work must begin with this book.&quot;Dr. Seuss: American Icon includes 103 pages of notes, index, and the most comprehensive annotated Seuss bibliography ever assembled. One learns a lot from this book; the author's lucid style makes it not only an enlightening work but a fun read.Philip Nel is the author of J. K. Rowling's Harry Potter Novels: A Reader's Guide (2001) and The Avant-Garde and American Postmodernity (2002).Roy E. Perry of Nolensville, Tennessee, is an advertising copywriter at a Nashville publishing house.|\n",
            "|0826414346|Dr. Seuss: American Icon      |NULL |A22X4XUPKF66MR|\"D. H. Richards \"\"ninthwavestore\"\"\"   |3/3               |4.0         |1107993600 |Good academic overview                         |\"Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art, cartoons, and the problems with the commercialization of the Seuss name and works after his death. It is not, to any real extent, a biography. Those seeking such should move on.As an academic book it leans on the dry side. It assumes the reader has a fairly good knowledge of Children's Literature and 20th Century cartoons (not the animated kind). Not a book to begin your Dr. Seuss experience with. But if you have read them to your children and are interested about the writing style (there is a good chapter about his poetry) or his art style (not as good a chapter, but still interesting).What interested me the most was the deconstruction of the recent rush to \"\"cash in\"\" on Seuss by Hollywood and advertisers. I think that Nel wants to come down against it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "+----------+------------------------------+-----+--------------+--------------------------------------+------------------+------------+-----------+-----------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the columns to understand what's inside\n",
        "\n",
        "cols = {c.lower(): c for c in ratings.columns}\n",
        "cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1CBoqGRAtYF",
        "outputId": "32503b0d-7cc0-40b7-ba9e-ea605a243be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'Id',\n",
              " 'title': 'Title',\n",
              " 'price': 'Price',\n",
              " 'user_id': 'User_id',\n",
              " 'profilename': 'profileName',\n",
              " 'review/helpfulness': 'review/helpfulness',\n",
              " 'review/score': 'review/score',\n",
              " 'review/time': 'review/time',\n",
              " 'review/summary': 'review/summary',\n",
              " 'review/text': 'review/text'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and select core columns\n",
        "from pyspark.sql import functions as functions\n",
        "\n",
        "score_string = functions.regexp_extract(functions.col(\"review/score\"), r\"([0-9]+(\\.[0-9]+)?)\", 1)\n",
        "\n",
        "ratings_0 = (\n",
        "    ratings\n",
        "    .select(\n",
        "        functions.col(\"User_id\").alias(\"user_id\"),\n",
        "        functions.col(\"Id\").alias(\"book_id\"),\n",
        "        # safe numeric extraction for odd strings\n",
        "        functions.when(score_string != \"\", score_string.cast(\"double\")).otherwise(F.lit(None).cast(\"double\")).alias(\"rating\"),\n",
        "        functions.col(\"Title\").alias(\"title\"),\n",
        "    )\n",
        "    .dropna(subset=[\"user_id\", \"book_id\", \"rating\"])\n",
        ")\n",
        "\n",
        "ratings_0.select(\"rating\").describe().show()\n",
        "ratings_0.show(3, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG9AavLqBqYJ",
        "outputId": "bb9ac40f-77e1-4319-dc0c-80d8b802d855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|            rating|\n",
            "+-------+------------------+\n",
            "|  count|           2433202|\n",
            "|   mean|2029.6013891366192|\n",
            "| stddev|1580342.9802411501|\n",
            "|    min|               0.0|\n",
            "|    max|        1.295568E9|\n",
            "+-------+------------------+\n",
            "\n",
            "+--------------+----------+------+------------------------------+\n",
            "|user_id       |book_id   |rating|title                         |\n",
            "+--------------+----------+------+------------------------------+\n",
            "|AVCGYZL8FQQTD |1882931173|4.0   |Its Only Art If Its Well Hung!|\n",
            "|A30TK6U7DNS82R|0826414346|5.0   |Dr. Seuss: American Icon      |\n",
            "|A3UH4UZ4RSVO82|0826414346|5.0   |Dr. Seuss: American Icon      |\n",
            "+--------------+----------+------+------------------------------+\n",
            "only showing top 3 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear bad formed data for ratings, first got 10^8 score\n",
        "\n",
        "# keep only realistic star ratings\n",
        "ratings_1 = ratings_0.filter((F.col(\"rating\") >= 1.0) & (F.col(\"rating\") <= 5.0))\n",
        "\n",
        "ratings_1.select(\"rating\").describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-3fI2--IBYv",
        "outputId": "94f9067d-b17c-40cc-d892-797e7871967f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|           rating|\n",
            "+-------+-----------------+\n",
            "|  count|          2426292|\n",
            "|   mean|4.222532572336718|\n",
            "| stddev|1.183760589211074|\n",
            "|    min|              1.0|\n",
            "|    max|              5.0|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.select(\"review/score\").show(5, truncate=False)\n",
        "ratings.select(\"review/helpfulness\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4POe1P5MGdiz",
        "outputId": "f077f7d3-cd0f-4a48-94a4-5533529cb511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|review/score|\n",
            "+------------+\n",
            "|4.0         |\n",
            "|5.0         |\n",
            "|5.0         |\n",
            "|4.0         |\n",
            "|4.0         |\n",
            "+------------+\n",
            "only showing top 5 rows\n",
            "+------------------+\n",
            "|review/helpfulness|\n",
            "+------------------+\n",
            "|7/7               |\n",
            "|10/10             |\n",
            "|10/11             |\n",
            "|7/7               |\n",
            "|3/3               |\n",
            "+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample and reduce sparcity, for speed\n",
        "\n",
        "ratings = ratings_1\n",
        "if not USE_FULL_DATA:\n",
        "    ratings = ratings.sample(False, SAMPLE_FRAC, seed=SEED)\n",
        "\n",
        "MIN_USER_RATINGS = 5\n",
        "MIN_BOOK_RATINGS = 5\n",
        "\n",
        "user_count = ratings.groupBy(\"user_id\").count().withColumnRenamed(\"count\", \"user_count\")\n",
        "book_count = ratings.groupBy(\"book_id\").count().withColumnRenamed(\"count\", \"book_count\")\n",
        "\n",
        "ratings = (\n",
        "    ratings.join(user_count, \"user_id\")\n",
        "     .join(book_count, \"book_id\")\n",
        "     .filter((functions.col(\"user_count\") >= MIN_USER_RATINGS) & (functions.col(\"book_count\") >= MIN_BOOK_RATINGS))\n",
        "     .select(\"user_id\", \"book_id\", \"rating\", \"title\")\n",
        ")\n",
        "\n",
        "print(\"rows:\", ratings.count())\n",
        "print(\"users:\", ratings.select(\"user_id\").distinct().count())\n",
        "print(\"books:\", ratings.select(\"book_id\").distinct().count())\n",
        "\n",
        "ratings.cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeQMoAYvHK3t",
        "outputId": "7406ad35-1c68-4261-fc5a-84c2eabb79e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows: 85603\n",
            "users: 9795\n",
            "books: 13660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, book_id: string, rating: double, title: string]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "ratings.groupBy(\"book_id\").count().orderBy(F.col(\"count\").desc()).show(20)\n",
        "ratings.groupBy(\"user_id\").count().orderBy(F.col(\"count\").desc()).show(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn_hmGfPR0ru",
        "outputId": "b710abca-667f-49b3-f573-0f3f57ad6383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|   book_id|count|\n",
            "+----------+-----+\n",
            "|0141804459|  178|\n",
            "|B000GQG7D2|  171|\n",
            "|B000NDSX6C|  168|\n",
            "|B000C1X8JC|  168|\n",
            "|0786135034|  167|\n",
            "|B000F6H01Q|  165|\n",
            "|B000GQG5MA|  164|\n",
            "|B000GDLGSG|  164|\n",
            "|B000ILIJE0|  164|\n",
            "|B000Q032UY|  164|\n",
            "|1844560333|  161|\n",
            "|B000NWQXBA|  159|\n",
            "|0451513967|  159|\n",
            "|0435126075|  158|\n",
            "|8188280046|  157|\n",
            "|1901768945|  157|\n",
            "|B000EVI8O0|  155|\n",
            "|1566190932|  150|\n",
            "|B000H9R1Q0|  148|\n",
            "|B000PC54NG|  145|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n",
            "+--------------+-----+\n",
            "|       user_id|count|\n",
            "+--------------+-----+\n",
            "|A1D2C0WDCSHUWZ|  568|\n",
            "|   AFVQZQ8PW0L|  290|\n",
            "|A14OJS0VWMOSWO|  266|\n",
            "|A20EEWWSFMZ1PN|  212|\n",
            "|A1X8VZWTOG8IS6|  211|\n",
            "| AHD101501WCN1|  184|\n",
            "|A1K1JW1C5CUSUZ|  179|\n",
            "|A1EKTLUL24HDG8|  145|\n",
            "|A1G37DFO8MQW0M|  143|\n",
            "|A1N1YEMTI9DJ86|  139|\n",
            "|A3QVAKVRAH657N|  136|\n",
            "| AHXAPVSHPJ6OJ|  132|\n",
            "|A2F6N60Z96CAJI|  131|\n",
            "|A1L43KWWR05PCS|  129|\n",
            "|A1T17LMQABMBN5|  117|\n",
            "|A319KYEIAZ3SON|  113|\n",
            "|A3M174IC0VXOS2|  111|\n",
            "| AJQ1S39GZBKUG|  109|\n",
            "|A3LKWMM12AF0PU|  108|\n",
            "|A28WJUJF6D2ULA|  107|\n",
            "+--------------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline recommender by popularity\n",
        "# Check it to compare later\n",
        "\n",
        "MIN_REVIEWS_FOR_POPULARITY = 10\n",
        "\n",
        "popular = (\n",
        "    ratings.groupBy(\"book_id\", \"title\")\n",
        "     .agg(functions.count(\"*\").alias(\"n\"), functions.avg(\"rating\").alias(\"average_rating\"))\n",
        "     .filter(functions.col(\"n\") >= MIN_REVIEWS_FOR_POPULARITY)\n",
        "     .orderBy(functions.col(\"average_rating\").desc(), functions.col(\"n\").desc())\n",
        ")\n",
        "\n",
        "popular.show(20, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtLBUJJJOFz5",
        "outputId": "14d8993f-cb17-44fb-ce77-36254bb75e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------------------------------------------------------------------------------+---+-----------------+\n",
            "|book_id   |title                                                                                    |n  |average_rating   |\n",
            "+----------+-----------------------------------------------------------------------------------------+---+-----------------+\n",
            "|B000OZRZ90|Milton's Paradise Lost                                                                   |12 |5.0              |\n",
            "|B000JWHH32|The Jungle Book (Companion Library)                                                      |11 |5.0              |\n",
            "|1854596209|Hamlet (The Shakespeare Folios)                                                          |11 |5.0              |\n",
            "|B0007J8XJ4|The varieties of religious experience: A study in human nature (Gifford lectures)        |10 |5.0              |\n",
            "|B0007G64NO|The Screwtape letters & Screwtape proposes a toast (Time reading program special edition)|10 |5.0              |\n",
            "|0877549249|Hamlet (Mod Crit Interpret) (Bloom's Modern Critical Interpretations)                    |16 |4.9375           |\n",
            "|B00088ZN1A|I, Claudius (Armed Services edition)                                                     |15 |4.933333333333334|\n",
            "|B000KOYWE6|The Heart of the Matter                                                                  |14 |4.928571428571429|\n",
            "|B0007FJEAK|Brideshead revisited: The sacred and profane memories of Captain Charles Ryder           |13 |4.923076923076923|\n",
            "|B000H0JB7Q|The Heart of the Matter                                                                  |12 |4.916666666666667|\n",
            "|B000MUCEDY|little house in the big woods                                                            |12 |4.916666666666667|\n",
            "|B00007FYQV|Red Storm Rising                                                                         |12 |4.916666666666667|\n",
            "|B000JMKVF8|Blood and Thunder: An Epic of the American West                                          |12 |4.916666666666667|\n",
            "|B0006EAC1C|Our man in Havana (Heron books)                                                          |12 |4.916666666666667|\n",
            "|B000I1VJLA|The Lord of the Rings Box Set                                                            |89 |4.910112359550562|\n",
            "|B0006DJX7W|Sources and extent of groundwater contamination (AG)                                     |11 |4.909090909090909|\n",
            "|B000KO327E|All Creatures Great and Small                                                            |11 |4.909090909090909|\n",
            "|B0007DRIT6|The richest man in Babylon                                                               |11 |4.909090909090909|\n",
            "|B000L2RXCK|All Creatures Great and Small                                                            |11 |4.909090909090909|\n",
            "|B0007EW5L6|Kon-tiki: Across the Pacific by raft (A Keith Jennison book)                             |11 |4.909090909090909|\n",
            "+----------+-----------------------------------------------------------------------------------------+---+-----------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "train_df, test_df = ratings.randomSplit([0.8, 0.2], seed=SEED)\n",
        "\n",
        "train_df = train_df.cache()\n",
        "test_df  = test_df.cache()\n",
        "\n",
        "print(\"train:\", train_df.count(), \"test:\", test_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv81aiKXP2pG",
        "outputId": "f8865840-d216-48c8-8aae-3728a7359637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 68307 test: 17296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Item-item colaborative filtering"
      ],
      "metadata": {
        "id": "jLmtaWrkmYrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build user to list of pairs item, rating from train data\n",
        "\n",
        "# resilient distr dataset\n",
        "train_rdd = train_df.select(\"user_id\", \"book_id\", \"rating\").rdd\n",
        "\n",
        "user_items = (\n",
        "    train_rdd\n",
        "    .map(lambda row: (row[\"user_id\"], (row[\"book_id\"], float(row[\"rating\"]))))\n",
        "    .groupByKey()\n",
        "    .mapValues(list)\n",
        ")\n"
      ],
      "metadata": {
        "id": "-AwG_631Rd9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate item pairs per user and get stats aggregation\n",
        "\n",
        "import itertools\n",
        "import math\n",
        "# safety cap for many reviews\n",
        "MAX_ITEMS_PER_USER = 50\n",
        "\n",
        "def make_pairs(items):\n",
        "    # items are list of (book_id, rating)\n",
        "    if len(items) > MAX_ITEMS_PER_USER:\n",
        "        items = items[:MAX_ITEMS_PER_USER]  # deterministic cap, todo: improve\n",
        "    out = []\n",
        "    for (i, ri), (j, rj) in itertools.combinations(items, 2):\n",
        "        if i == j:\n",
        "            continue\n",
        "        a, b = (i, j) if i < j else (j, i)\n",
        "        ra, rb = (ri, rj) if i < j else (rj, ri)\n",
        "        out.append(((a, b), (ra*rb, ra*ra, rb*rb, 1)))\n",
        "    return out\n",
        "\n",
        "pair_stats = (\n",
        "    user_items\n",
        "    .flatMap(lambda x: make_pairs(x[1]))\n",
        "    .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1], x[2]+y[2], x[3]+y[3]))\n",
        ")\n"
      ],
      "metadata": {
        "id": "2SI7rd7Wmo_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity\n",
        "\n",
        "MIN_COMMON_USERS = 2\n",
        "\n",
        "similarities = (\n",
        "    pair_stats\n",
        "    .filter(lambda kv: kv[1][3] >= MIN_COMMON_USERS)\n",
        "    .mapValues(lambda v: (\n",
        "        v[0] / (math.sqrt(v[1]) * math.sqrt(v[2]) + 1e-12),  # cosine similarity\n",
        "        v[3]  # common users\n",
        "    ))\n",
        ")\n",
        "\n",
        "print(\"number of item pairs with common users >= min common users:\", similarities.count())\n",
        "print(\"sample similarity:\", similarities.take(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se_7XGEnm9vQ",
        "outputId": "d6162163-9101-4c8c-8e23-b996c91680ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of item pairs with common users >= min common users: 22827\n",
            "sample similarity: [(('1420926810', '1570020981'), (0.9374252720097401, 2)), (('1841490717', 'B000N7204Y'), (0.986025143961732, 3)), (('0792717848', 'B00005QTHG'), (0.8531145054348057, 3)), (('076240552X', 'B000MZCJUM'), (0.9999999999999929, 6)), (('B000LEPWGC', 'B000NUA82W'), (0.9938837346735968, 2))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BETA = 10  # larger = more conservative\n",
        "\n",
        "def significance(sim, cnt, beta=BETA):\n",
        "    shrink = cnt / (cnt + beta)\n",
        "    sim_w = sim * shrink\n",
        "    return sim_w, shrink, cnt\n"
      ],
      "metadata": {
        "id": "Eu5OiyyN-nJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN per item, top\n",
        "\n",
        "K = 30\n",
        "\n",
        "neighbors = similarities.flatMap(lambda kv: [\n",
        "    (kv[0][0], (kv[0][1],) + significance(kv[1][0], kv[1][1])),  # i -> (j, sim_w, shrink, cnt)\n",
        "    (kv[0][1], (kv[0][0],) + significance(kv[1][0], kv[1][1]))   # j -> (i, sim_w, shrink, cnt)\n",
        "])\n",
        "\n",
        "def topk(xs, k=K):\n",
        "    # t[1] is sim'\n",
        "    xs = sorted(xs, key=lambda t: t[1], reverse=True)\n",
        "    return xs[:k]\n",
        "\n",
        "item_neighbors = neighbors.groupByKey().mapValues(lambda xs: topk(list(xs), K))\n",
        "\n",
        "# collect is ok at this sample size\n",
        "item_neighbors_map = dict(item_neighbors.collect())\n",
        "print(\"items with neighbor lists:\", len(item_neighbors_map))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VrM3KjvnWBo",
        "outputId": "5de8f2e2-e428-48f1-b313-4cdc41bc0986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items with neighbor lists: 4753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcast!!\n",
        "\n",
        "broadcast_neighbours = spark.sparkContext.broadcast(item_neighbors_map)"
      ],
      "metadata": {
        "id": "rzZtQln_nts_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ui = (\n",
        "    train_df.groupBy(\"user_id\", \"book_id\")\n",
        "            .agg(functions.avg(\"rating\").alias(\"rating\"))\n",
        ")\n",
        "\n",
        "# Broadcast user history from train\n",
        "user_history_map = dict(\n",
        "    train_ui.rdd\n",
        "    .map(lambda r: (r[\"user_id\"], (r[\"book_id\"], float(r[\"rating\"]))))\n",
        "    .groupByKey()\n",
        "    .mapValues(list)\n",
        "    .collect()\n",
        ")\n",
        "\n",
        "broadcast_history = spark.sparkContext.broadcast(user_history_map)\n",
        "print(\"users in history:\", len(user_history_map))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRfLU0W8ocxH",
        "outputId": "5bfba9d3-adfe-4b90-9cfd-50ac7e9ba281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "users in history: 9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def predict_one(user_id, target_item):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    neighbours = broadcast_neighbours.value.get(target_item, [])\n",
        "    if not history or not neighbours:\n",
        "        return None\n",
        "\n",
        "    history_map = dict(history)\n",
        "\n",
        "    num = 0.0\n",
        "    den = 0.0\n",
        "    for j, sim_w, shrink, cnt in neighbours:\n",
        "        if j in history_map:\n",
        "            num += sim_w * history_map[j]\n",
        "            den += abs(sim_w)\n",
        "\n",
        "    if den < 1e-9:\n",
        "        return None\n",
        "\n",
        "    prediction = num / den\n",
        "    return max(1.0, min(5.0, prediction))\n",
        "\n",
        "predicted_test_true = (\n",
        "    test_df.select(\"user_id\",\"book_id\",\"rating\").rdd\n",
        "    .map(lambda r: (predict_one(r[\"user_id\"], r[\"book_id\"]), float(r[\"rating\"])))\n",
        "    .filter(lambda x: x[0] is not None)\n",
        ")\n",
        "\n",
        "mse = predicted_test_true.map(lambda x: (x[0] - x[1])**2).mean()\n",
        "rmse = math.sqrt(mse)\n",
        "\n",
        "predicted_count = predicted_test_true.count()\n",
        "test_count = test_df.count()\n",
        "coverage = predicted_count / test_count\n",
        "\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"Coverage:\", coverage)\n",
        "print(\"Predicted test points:\", predicted_count, \"/\", test_count)\n"
      ],
      "metadata": {
        "id": "GoV6TdqHs4il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05019713-f060-4134-f18c-01b930a709e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4100855556182296\n",
            "Coverage: 0.38806660499537465\n",
            "Predicted test points: 6712 / 17296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COverage improved significantly.\n",
        "Now Baseline RMSE"
      ],
      "metadata": {
        "id": "Wc_yOfCb3Tus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from pyspark.sql import functions as functions\n",
        "\n",
        "global_mean = train_df.agg(functions.avg(\"rating\")).first()[0]\n",
        "baseline_mse = test_df.select(\"rating\").rdd.map(lambda r: (float(r[0]) - global_mean)**2).mean()\n",
        "baseline_rmse = math.sqrt(baseline_mse)\n",
        "\n",
        "print(\"Global mean:\", global_mean)\n",
        "print(\"Baseline RMSE (global mean):\", baseline_rmse)\n"
      ],
      "metadata": {
        "id": "92kA8kgxug8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ce1b9f-1d96-48a7-9e13-a12c5924e6e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mean: 4.2634137057695405\n",
            "Baseline RMSE (global mean): 1.0191472853605235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top N recommendations for a user\n",
        "book_titles = dict(\n",
        "    ratings.select(\"book_id\", \"title\")\n",
        "           .dropna(subset=[\"title\"])\n",
        "           .dropDuplicates([\"book_id\"])\n",
        "           .rdd.map(lambda r: (r[\"book_id\"], r[\"title\"]))\n",
        "           .collect()\n",
        ")\n",
        "\n",
        "print(\"book titles len:\", len(book_titles))\n"
      ],
      "metadata": {
        "id": "NNL-neCB3Pvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea885b6-a691-46e9-b147-ba02c4b456fa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "book titles len: 13659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_user(user_id, N=10):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    # cold start\n",
        "    if not history:\n",
        "        return []\n",
        "\n",
        "    seen = set(i for i, _ in history)\n",
        "    # item -> (num, den, contribs)\n",
        "    scores = {}\n",
        "\n",
        "    for i, r_ui in history:\n",
        "        for j, sim_w, shrink, count in broadcast_neighbours.value.get(i, []):\n",
        "            if j in seen:\n",
        "                continue\n",
        "            num, den, c = scores.get(j, (0.0, 0.0, 0))\n",
        "            num += sim_w * r_ui\n",
        "            den += abs(sim_w)\n",
        "            c += 1\n",
        "            scores[j] = (num, den, c)\n",
        "\n",
        "    predictions = []\n",
        "    for j, (num, den, c) in scores.items():\n",
        "        if den > 1e-9 and c >= 2:  # small filter makes output nicer\n",
        "            prediction = max(1.0, min(5.0, num / den))\n",
        "            predictions.append((j, prediction, c))\n",
        "\n",
        "    predictions.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "    return predictions[:N]\n"
      ],
      "metadata": {
        "id": "HrNew0TO3pbb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick one of the users and ptint top rated\n",
        "\n",
        "def top_rated_unique(user_id, n=10):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    # sort by rating, then unique by book_id\n",
        "    history = sorted(history, key=lambda x: x[1], reverse=True)\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for bid, r in history:\n",
        "        if bid in seen:\n",
        "            continue\n",
        "        seen.add(bid)\n",
        "        out.append((bid, r))\n",
        "        if len(out) >= n:\n",
        "            break\n",
        "    return out\n",
        "\n",
        "USER = \"A1D2C0WDCSHUWZ\"\n",
        "for bid, r in top_rated_unique(USER, 10):\n",
        "    print(f\"{r:.1f}  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n"
      ],
      "metadata": {
        "id": "daycYO3F4BvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0dc32d-7e61-490e-9cfc-b9fc50a8fcde"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0  B000H9R1Q0  -  The Hobbit\n",
            "5.0  B000Q032UY  -  The Hobbit or There and Back Again\n",
            "5.0  9626346949  -  Little Women (Junior Classics)\n",
            "5.0  B000H7EO2G  -  The Lord of the Rings Trilogy 3 Volumes\n",
            "5.0  B0007NMYQ8  -  The Two Princesses of Bamarre\n",
            "5.0  B000C1X8JC  -  Pride and Prejudice\n",
            "5.0  B000F6H01Q  -  Pride and Prejudice\n",
            "5.0  B000MPEZ9K  -  Emma\n",
            "5.0  B000Q382GK  -  The Lion, the Witch and the Wardrobe: A Story for Children\n",
            "5.0  0395051150  -  Emma (Riverside Editions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SO, he is hitting 5/5 often\n",
        "# Let's check what user liked\n",
        "\n",
        "\n",
        "recommendations = recommend_for_user(USER, 10)\n",
        "for bid, prediction, c in recommendations:\n",
        "    print(f\"{prediction:.3f} (from {c} neighbour)  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n"
      ],
      "metadata": {
        "id": "Ebzzmz3C6i-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2125ee60-bacb-443a-a2fa-e463fda8a84b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.000 (from 35 neighbour)  1566190932  -  Pride and Prejudice\n",
            "5.000 (from 25 neighbour)  B000EVI8O0  -  Pride and Prejudice\n",
            "5.000 (from 13 neighbour)  9626341823  -  A Christmas Carol (Classic Fiction)\n",
            "5.000 (from 12 neighbour)  0140860282  -  Wuthering Heights (Penguin Audiobooks)\n",
            "5.000 (from 10 neighbour)  B000Q08CDQ  -  Return of the King Being the Third Part of The Lord of the Rings\n",
            "5.000 (from 9 neighbour)  B0006AQ4LI  -  Wuthering Heights\n",
            "5.000 (from 8 neighbour)  1590862899  -  The Scarlet Letter\n",
            "5.000 (from 8 neighbour)  B000N6DDJQ  -  The Scarlet Letter A Romance\n",
            "5.000 (from 7 neighbour)  1593351348  -  Wuthering Heights\n",
            "5.000 (from 7 neighbour)  0435126083  -  Wuthering Heights (New Windmill)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check abother user\n",
        "\n",
        "USER = \"A14OJS0VWMOSWO\"\n",
        "for bid, r in top_rated_unique(USER, 40):\n",
        "    print(f\"{r:.1f}  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n",
        "\n",
        "recommendations = recommend_for_user(USER, 40)\n",
        "for bid, prediction, c in recommendations:\n",
        "    print(f\"{prediction:.3f} (from {c} neighbour)  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yY__kTbe4xn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ef07ac-820f-43ca-e295-fbb16693b767"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0  B000PJLA96  -  Understanding Exposure\n",
            "5.0  0873529871  -  MLA Handbook for Writers of Research Papers (Sixth Edition Large Print)\n",
            "5.0  0394779959  -  Summer of My German Soldier\n",
            "5.0  1574904558  -  Lauren's Story: An American Dog in Paris (Beeler Large Print Series)\n",
            "5.0  1559270845  -  The Womanly Art of Breastfeeding\n",
            "5.0  0192817728  -  The Secret Garden (Worlds Classics)\n",
            "5.0  193011088X  -  Swing, Second Edition\n",
            "5.0  B000NWKKAU  -  The A. B. C. Murders\n",
            "5.0  0970540116  -  Flour Power: A Guide To Modern Home Grain Milling\n",
            "5.0  1400053684  -  Countdown to Crisis: The Coming Nuclear Showdown with Iran\n",
            "5.0  B000FFJSO4  -  Priestess Of Avalon\n",
            "5.0  B000GLVRLY  -  Suzannes Diary For Nicholas\n",
            "5.0  0921165730  -  Vitamin C for a Healthy Workplace\n",
            "5.0  B0006Y0EN8  -  The running man\n",
            "5.0  B00007FYA3  -  Practical Standards for Microsoft Visual Basic\n",
            "5.0  B0006APKUO  -  Rebecca\n",
            "5.0  0140298401  -  Forever Liesl: A Memoir of The Sound of Music\n",
            "5.0  0971953880  -  When You Work for a Bully: Assessing Your Options and Taking Action\n",
            "5.0  B000K9K5PQ  -  MIRACLES ON MAPLE HILL\n",
            "5.0  B000N8RIMC  -  I'm a Manatee\n",
            "5.0  0814782922  -  American Freemasons: Three Centuries of Building Communities\n",
            "5.0  0970664508  -  Starting a Collection Agency\n",
            "5.0  B000OVTKUG  -  Star Wars Dark Nest I\n",
            "5.0  1568959761  -  The Art of Happiness\n",
            "5.0  B000IEZE3G  -  Harry Potter and The Sorcerer's Stone\n",
            "5.0  B000F6UI06  -  Fidgety Fish (Book and Audio CD) (Paperback)\n",
            "5.0  B000PGTEYW  -  The Perennial Gardener's Design Primer\n",
            "5.0  0393062139  -  A Mind of its Own: How Your Brain Distorts and Deceives\n",
            "5.0  0425209768  -  Braced2Bite\n",
            "5.0  B0006QSHNA  -  The little prince\n",
            "5.0  B0006WXO4G  -  ABC for book-collectors\n",
            "5.0  B000JMKTK0  -  Imperial Life in the Emerald City\n",
            "5.0  0929701712  -  Beneath a Marble Sky: A Novel of the Taj Mahal\n",
            "5.0  B000P1AYVE  -  LONELY MEN (SACKETTS)\n",
            "5.0  B000J17QRK  -  The Freemasons: A History of the World's Most Powerful Secret Society\n",
            "5.0  1559391766  -  Healing With Form, Energy, And Light: The Five Elements In Tibetan Shamanism, Tantra, And Dzogchen\n",
            "5.0  B0000ALQ1B  -  The Girls: Sappho Goes to Hollywood\n",
            "5.0  B000L9Z0DC  -  No Place Like Home\n",
            "5.0  0613659155  -  Nights In Rodanthe (Turtleback School & Library Binding Edition)\n",
            "5.0  0595310176  -  The 7 Keys to a Dream Job: A Career Nirvana Playbook!\n",
            "5.000 (from 5 neighbour)  140505347X  -  Alice's Adventures in Wonderland\n",
            "5.000 (from 4 neighbour)  B000H9R1Q0  -  The Hobbit\n",
            "5.000 (from 4 neighbour)  B000GQG5MA  -  The Hobbit; Or, There and Back Again\n",
            "5.000 (from 4 neighbour)  B000CEDH40  -  Lewis Carroll's Alice in Wonderland\n",
            "5.000 (from 4 neighbour)  0904724719  -  Alice in Wonderland (Tell tales)\n",
            "5.000 (from 4 neighbour)  0786261080  -  Alice's Adventures in Wonderland\n",
            "5.000 (from 4 neighbour)  B000IOKF8U  -  \"Alice\"\"s Adventures in Wonderland\"\n",
            "5.000 (from 4 neighbour)  068983375X  -  Alice's Adventures in Wonderland (Aladdin Classics)\n",
            "5.000 (from 3 neighbour)  0451519582  -  Wuthering Heights (Signet classics)\n",
            "5.000 (from 3 neighbour)  9626346949  -  Little Women (Junior Classics)\n",
            "5.000 (from 3 neighbour)  B000NNOTXI  -  To Kill a Mocking Bird\n",
            "5.000 (from 3 neighbour)  B000GY0PV4  -  The Two Towers\n",
            "5.000 (from 3 neighbour)  B000TZ19TC  -  Fahrenheit 451\n",
            "5.000 (from 3 neighbour)  B000MS82OQ  -  Mere Christianity\n",
            "5.000 (from 3 neighbour)  0748608370  -  Treasure Island\n",
            "5.000 (from 3 neighbour)  0736668039  -  The Lost World\n",
            "5.000 (from 2 neighbour)  B0006BV75A  -  Little women;: Or, Meg, Jo, Beth, and Amy\n",
            "5.000 (from 2 neighbour)  B0007EGQ52  -  Little women: Or Meg, Jo, Beth, and Amy\n",
            "5.000 (from 2 neighbour)  B0008CXTHG  -  Little women: Or, Meg, Jo, Beth, and Amy\n",
            "5.000 (from 2 neighbour)  0939495848  -  Treasure Island\n",
            "5.000 (from 2 neighbour)  0395051150  -  Emma (Riverside Editions)\n",
            "5.000 (from 2 neighbour)  B0006AGHH4  -  Uncle Tom's cabin;: Or, Life among the lowly\n",
            "5.000 (from 2 neighbour)  0754053539  -  A Passage to India\n",
            "5.000 (from 2 neighbour)  B0007C10MS  -  The great Gatsby (Leading English literature library)\n",
            "5.000 (from 2 neighbour)  B0007DRGI4  -  To kill a mockingbird\n",
            "5.000 (from 2 neighbour)  0451518845  -  Jane Eyre (Signet classics)\n",
            "5.000 (from 2 neighbour)  0140351310  -  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "5.000 (from 2 neighbour)  1847022251  -  Jane Eyre (Large Print)\n",
            "5.000 (from 2 neighbour)  B000Q6XPDW  -  The Poisonwood Bible\n",
            "5.000 (from 2 neighbour)  B000K7WNQW  -  To Kill a Mockingbird\n",
            "5.000 (from 2 neighbour)  0816156921  -  Dracula (G. K. Hall (Large Print))\n",
            "5.000 (from 2 neighbour)  0134354575  -  Wuthering Heights\n",
            "5.000 (from 2 neighbour)  0613334582  -  The Alchemist: A Fable about Following Your Dream\n",
            "5.000 (from 2 neighbour)  B000NPEWHE  -  Harry Potter and the Chamber of Secrets\n",
            "5.000 (from 2 neighbour)  B000H7EO2G  -  The Lord of the Rings Trilogy 3 Volumes\n",
            "5.000 (from 2 neighbour)  B000FAIRN2  -  The Lord Of The Rings THREE VOLUME BOXED SET (The Fellowship Of The Ring, The Return of The King, The Two towers)\n",
            "5.000 (from 2 neighbour)  B000PIIMPW  -  The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\n",
            "5.000 (from 2 neighbour)  B000I1VJLA  -  The Lord of the Rings Box Set\n",
            "5.000 (from 2 neighbour)  B000PMCF1A  -  The Catcher in the Rye [Audiobook] [Cd] [Unabridged] (Audio CD)\n",
            "5.000 (from 2 neighbour)  B000HLFD4K  -  The Great Gatsby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recommend for user and dont clip at 5.0 for display\n",
        "def recommend_for_user(user_id, N=10):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    if not history:\n",
        "        return []\n",
        "\n",
        "    seen = set(i for i, _ in history)\n",
        "    scores = {}\n",
        "\n",
        "    for i, r_ui in history:\n",
        "        for j, sim_w, shrink, count in broadcast_neighbours.value.get(i, []):\n",
        "            if j in seen:\n",
        "                continue\n",
        "            num, den, c = scores.get(j, (0.0, 0.0, 0))\n",
        "            num += sim_w * r_ui\n",
        "            den += abs(sim_w)\n",
        "            c += 1\n",
        "            scores[j] = (num, den, c)\n",
        "\n",
        "    predictions = []\n",
        "    for j, (num, den, c) in scores.items():\n",
        "        if den > 1e-9 and c >= 2:\n",
        "            raw = num / den\n",
        "            clipped = max(1.0, min(5.0, raw))\n",
        "            predictions.append((j, raw, clipped, c))\n",
        "\n",
        "    # sort by clipped then contribs\n",
        "    predictions.sort(key=lambda x: (x[2], x[3]), reverse=True)\n",
        "    return predictions[:N]\n",
        "\n",
        "recommendations = recommend_for_user(USER, 200)\n",
        "for bid, raw, clipped, c in recommendations:\n",
        "    print(f\"{clipped:.3f} (raw {raw:.3f}, from {c} neigh)  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n"
      ],
      "metadata": {
        "id": "SOp_AOZd8QyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590948af-fe64-4348-9b70-14ad29fd8acd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.000 (raw 5.000, from 5 neigh)  140505347X  -  Alice's Adventures in Wonderland\n",
            "5.000 (raw 5.000, from 4 neigh)  B000H9R1Q0  -  The Hobbit\n",
            "5.000 (raw 5.000, from 4 neigh)  B000GQG5MA  -  The Hobbit; Or, There and Back Again\n",
            "5.000 (raw 5.000, from 4 neigh)  B000CEDH40  -  Lewis Carroll's Alice in Wonderland\n",
            "5.000 (raw 5.000, from 4 neigh)  0904724719  -  Alice in Wonderland (Tell tales)\n",
            "5.000 (raw 5.000, from 4 neigh)  0786261080  -  Alice's Adventures in Wonderland\n",
            "5.000 (raw 5.000, from 4 neigh)  B000IOKF8U  -  \"Alice\"\"s Adventures in Wonderland\"\n",
            "5.000 (raw 5.000, from 4 neigh)  068983375X  -  Alice's Adventures in Wonderland (Aladdin Classics)\n",
            "5.000 (raw 5.000, from 3 neigh)  0451519582  -  Wuthering Heights (Signet classics)\n",
            "5.000 (raw 5.000, from 3 neigh)  9626346949  -  Little Women (Junior Classics)\n",
            "5.000 (raw 5.000, from 3 neigh)  B000NNOTXI  -  To Kill a Mocking Bird\n",
            "5.000 (raw 5.000, from 3 neigh)  B000GY0PV4  -  The Two Towers\n",
            "5.000 (raw 5.000, from 3 neigh)  B000TZ19TC  -  Fahrenheit 451\n",
            "5.000 (raw 5.000, from 3 neigh)  B000MS82OQ  -  Mere Christianity\n",
            "5.000 (raw 5.000, from 3 neigh)  0748608370  -  Treasure Island\n",
            "5.000 (raw 5.000, from 3 neigh)  0736668039  -  The Lost World\n",
            "5.000 (raw 5.000, from 2 neigh)  B0006BV75A  -  Little women;: Or, Meg, Jo, Beth, and Amy\n",
            "5.000 (raw 5.000, from 2 neigh)  B0007EGQ52  -  Little women: Or Meg, Jo, Beth, and Amy\n",
            "5.000 (raw 5.000, from 2 neigh)  B0008CXTHG  -  Little women: Or, Meg, Jo, Beth, and Amy\n",
            "5.000 (raw 5.000, from 2 neigh)  0939495848  -  Treasure Island\n",
            "5.000 (raw 5.000, from 2 neigh)  0395051150  -  Emma (Riverside Editions)\n",
            "5.000 (raw 5.000, from 2 neigh)  B0006AGHH4  -  Uncle Tom's cabin;: Or, Life among the lowly\n",
            "5.000 (raw 5.000, from 2 neigh)  0754053539  -  A Passage to India\n",
            "5.000 (raw 5.000, from 2 neigh)  B0007C10MS  -  The great Gatsby (Leading English literature library)\n",
            "5.000 (raw 5.000, from 2 neigh)  B0007DRGI4  -  To kill a mockingbird\n",
            "5.000 (raw 5.000, from 2 neigh)  0451518845  -  Jane Eyre (Signet classics)\n",
            "5.000 (raw 5.000, from 2 neigh)  0140351310  -  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "5.000 (raw 5.000, from 2 neigh)  1847022251  -  Jane Eyre (Large Print)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000Q6XPDW  -  The Poisonwood Bible\n",
            "5.000 (raw 5.000, from 2 neigh)  B000K7WNQW  -  To Kill a Mockingbird\n",
            "5.000 (raw 5.000, from 2 neigh)  0816156921  -  Dracula (G. K. Hall (Large Print))\n",
            "5.000 (raw 5.000, from 2 neigh)  0134354575  -  Wuthering Heights\n",
            "5.000 (raw 5.000, from 2 neigh)  0613334582  -  The Alchemist: A Fable about Following Your Dream\n",
            "5.000 (raw 5.000, from 2 neigh)  B000NPEWHE  -  Harry Potter and the Chamber of Secrets\n",
            "5.000 (raw 5.000, from 2 neigh)  B000H7EO2G  -  The Lord of the Rings Trilogy 3 Volumes\n",
            "5.000 (raw 5.000, from 2 neigh)  B000FAIRN2  -  The Lord Of The Rings THREE VOLUME BOXED SET (The Fellowship Of The Ring, The Return of The King, The Two towers)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000PIIMPW  -  The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000I1VJLA  -  The Lord of the Rings Box Set\n",
            "5.000 (raw 5.000, from 2 neigh)  B000PMCF1A  -  The Catcher in the Rye [Audiobook] [Cd] [Unabridged] (Audio CD)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000HLFD4K  -  The Great Gatsby\n",
            "5.000 (raw 5.000, from 2 neigh)  B000MVXQMG  -  Thinner\n",
            "5.000 (raw 5.000, from 2 neigh)  B000GQK706  -  The Lord of the Rings - Boxed Set\n",
            "5.000 (raw 5.000, from 2 neigh)  0865472637  -  The Hound of the Baskervilles\n",
            "5.000 (raw 5.000, from 2 neigh)  0451504682  -  The Canterbury Tales\n",
            "5.000 (raw 5.000, from 2 neigh)  0898455537  -  Cry, the Beloved Country (Alan Paton Reads)\n",
            "5.000 (raw 5.000, from 2 neigh)  0460872702  -  Great Gatsby (Everyman)\n",
            "5.000 (raw 5.000, from 2 neigh)  B0006AQG7U  -  The time machine,: An invention,\n",
            "5.000 (raw 5.000, from 2 neigh)  B000NWQXBA  -  The Hobbit\n",
            "5.000 (raw 5.000, from 2 neigh)  0848809904  -  Lost World\n",
            "5.000 (raw 5.000, from 2 neigh)  B000H0BNVI  -  The Bourne Identity\n",
            "5.000 (raw 5.000, from 2 neigh)  1566190932  -  Pride and Prejudice\n",
            "5.000 (raw 5.000, from 2 neigh)  B00086VHAI  -  The confessions of St. Augustine (The Harvard classics)\n",
            "5.000 (raw 5.000, from 2 neigh)  1557424470  -  The Picture of Dorian Gray\n",
            "5.000 (raw 5.000, from 2 neigh)  B000H23TLS  -  The Bourne Supremacy\n",
            "5.000 (raw 5.000, from 2 neigh)  B000GXSLIY  -  Tarzan of the Apes (Vol 1)\n",
            "5.000 (raw 5.000, from 2 neigh)  9626346825  -  A Christmas Carol (Classic Fiction)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000N28H2I  -  The Two Towers\n",
            "5.000 (raw 5.000, from 2 neigh)  B000NYRZ42  -  A CHRISTMAS CAROL, BEING A GHOST STORY OF CHRISTMAS\n",
            "5.000 (raw 5.000, from 2 neigh)  0435126075  -  Pride & Prejudice (New Windmill)\n",
            "5.000 (raw 5.000, from 2 neigh)  0394603753  -  Catch-Twenty-Two\n",
            "5.000 (raw 5.000, from 2 neigh)  B0006BV6RY  -  Wuthering Heights (College classics in English)\n",
            "5.000 (raw 5.000, from 2 neigh)  1593974361  -  The Outlaw Sea: A World of Freedom, Chaos, and Crime\n",
            "5.000 (raw 5.000, from 2 neigh)  B000PCDFTQ  -  The ABC Murders\n",
            "5.000 (raw 5.000, from 4 neigh)  B000NDSX6C  -  The Hobbit\n",
            "5.000 (raw 5.000, from 4 neigh)  0517124203  -  Alice's Adventures in Wonderland\n",
            "5.000 (raw 5.000, from 3 neigh)  B000Q032UY  -  The Hobbit or There and Back Again\n",
            "5.000 (raw 5.000, from 3 neigh)  B000GQG7D2  -  The Hobbit\n",
            "5.000 (raw 5.000, from 2 neigh)  B000FFQ85G  -  Jane Eyre / Wuthering Heights\n",
            "5.000 (raw 5.000, from 2 neigh)  0451521196  -  Wuthering Heights (Signet classics)\n",
            "5.000 (raw 5.000, from 2 neigh)  B000GR11XM  -  Great Expectations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean centered item item\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "user_mean_map = dict(\n",
        "    train_df.groupBy(\"user_id\")\n",
        "            .agg(F.avg(\"rating\").alias(\"mu\"))\n",
        "            .rdd.map(lambda r: (r[\"user_id\"], float(r[\"mu\"])))\n",
        "            .collect()\n",
        ")\n",
        "bum = spark.sparkContext.broadcast(user_mean_map)\n",
        "\n",
        "print(\"users with mean:\", len(user_mean_map))\n"
      ],
      "metadata": {
        "id": "xivxmwPG8vha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900af58c-7861-47ee-ad09-679a3ee529bb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "users with mean: 9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean centered predictor\n",
        "\n",
        "def predict_one_centered(user_id, target_item):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    neighbours = broadcast_neighbours.value.get(target_item, [])\n",
        "    if not history or not neighbours:\n",
        "        return None\n",
        "\n",
        "    mu = bum.value.get(user_id, 4.0)\n",
        "    history_map = dict(history)\n",
        "\n",
        "    num = 0.0\n",
        "    den = 0.0\n",
        "    contribution = 0\n",
        "\n",
        "    for j, sim_w, shrink, count in neighbours:\n",
        "        if j in history_map:\n",
        "            num += sim_w * (history_map[j] - mu)   # deviation from user mean\n",
        "            den += abs(sim_w)\n",
        "            contribution += 1\n",
        "\n",
        "    if den < 1e-9:\n",
        "        return None\n",
        "\n",
        "    prediction = mu + num / den\n",
        "    prediction = max(1.0, min(5.0, prediction))\n",
        "    return prediction, contribution\n"
      ],
      "metadata": {
        "id": "pje5T94E99NC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recompute RMSE and coverage with mean centered predictor\n",
        "import math\n",
        "\n",
        "predicted_true = (\n",
        "    test_df.select(\"user_id\",\"book_id\",\"rating\").rdd\n",
        "    .map(lambda r: (predict_one_centered(r[\"user_id\"], r[\"book_id\"]), float(r[\"rating\"])))\n",
        "    .filter(lambda x: x[0] is not None)\n",
        "    .map(lambda x: (x[0][0], x[1]))  # keep only pred, true\n",
        ")\n",
        "\n",
        "mse = predicted_true.map(lambda x: (x[0] - x[1])**2).mean()\n",
        "rmse_centered = math.sqrt(mse)\n",
        "\n",
        "predicted_count = predicted_true.count()\n",
        "test_count = test_df.count()\n",
        "coverage_centered = predicted_count / test_count\n",
        "\n",
        "print(\"Centered RMSE:\", rmse_centered)\n",
        "print(\"Centered Coverage:\", coverage_centered)\n",
        "print(\"Predicted:\", predicted_count, \"/\", test_count)\n"
      ],
      "metadata": {
        "id": "E2BzJ1Oj-FzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e352d3-cc12-4d11-fb76-1cfa51e6a0ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centered RMSE: 0.4100855556182296\n",
            "Centered Coverage: 0.38806660499537465\n",
            "Predicted: 6712 / 17296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean centered top N recommendations\n",
        "def recommend_for_user_centered(user_id, N=10, min_contrib=2):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    if not history:\n",
        "        return []\n",
        "\n",
        "    mu = bum.value.get(user_id, 4.0)\n",
        "    seen = set(i for i, _ in history)\n",
        "    history_map = dict(history)\n",
        "\n",
        "    scores = {}  # item -> (num, den, contrib)\n",
        "    for i, r_ui in history:\n",
        "        for j, sim_w, shrink, count in broadcast_neighbours.value.get(i, []):\n",
        "            if j in seen:\n",
        "                continue\n",
        "            num, den, c = scores.get(j, (0.0, 0.0, 0))\n",
        "            num += sim_w * (history_map[i] - mu)   # use deviation\n",
        "            den += abs(sim_w)\n",
        "            c += 1\n",
        "            scores[j] = (num, den, c)\n",
        "\n",
        "    predictions = []\n",
        "    for j, (num, den, c) in scores.items():\n",
        "        if den > 1e-9 and c >= min_contrib:\n",
        "            prediction = mu + num / den\n",
        "            prediction = max(1.0, min(5.0, prediction))\n",
        "            predictions.append((j, prediction, c))\n",
        "\n",
        "    predictions.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "    return predictions[:N]\n"
      ],
      "metadata": {
        "id": "UrUw0KId-LvF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER = \"A3M174IC0VXOS2\"\n",
        "recommendations = recommend_for_user_centered(USER, 100)\n",
        "\n",
        "for bid, prediction, c in recommendations:\n",
        "    print(f\"{prediction:.3f} (from {c} neigh)  {bid}  -  {book_titles.get(bid, '<no title>')}\")\n"
      ],
      "metadata": {
        "id": "FnetTZzD-gQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300532a9-a422-41ba-e691-815235bbcd8f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.000 (from 4 neigh)  0451519582  -  Wuthering Heights (Signet classics)\n",
            "5.000 (from 4 neigh)  0435126075  -  Pride & Prejudice (New Windmill)\n",
            "5.000 (from 4 neigh)  0140860282  -  Wuthering Heights (Penguin Audiobooks)\n",
            "5.000 (from 4 neigh)  0134354575  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  B000FFQ85G  -  Jane Eyre / Wuthering Heights\n",
            "5.000 (from 3 neigh)  B000F6H01Q  -  Pride and Prejudice\n",
            "5.000 (from 3 neigh)  B000P4Q3JS  -  Wuthering Heights (The Franklin Library)\n",
            "5.000 (from 3 neigh)  B0007C10MS  -  The great Gatsby (Leading English literature library)\n",
            "5.000 (from 3 neigh)  0140351310  -  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "5.000 (from 3 neigh)  0451518845  -  Jane Eyre (Signet classics)\n",
            "5.000 (from 3 neigh)  0681994851  -  Jane Eyre\n",
            "5.000 (from 3 neigh)  0435126083  -  Wuthering Heights (New Windmill)\n",
            "5.000 (from 3 neigh)  1593355548  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  1591090245  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  1901768945  -  Pride and Prejudice\n",
            "5.000 (from 3 neigh)  0736605010  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  1569602093  -  Wuthering Heights.\n",
            "5.000 (from 3 neigh)  0894714805  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  1582790337  -  Wuthering Heights\n",
            "5.000 (from 3 neigh)  B000PMCF1A  -  The Catcher in the Rye [Audiobook] [Cd] [Unabridged] (Audio CD)\n",
            "5.000 (from 3 neigh)  B0000632ZL  -  The Summons\n",
            "5.000 (from 2 neigh)  B000NPAT6W  -  Narrative of the Life of Frederick Douglass, An American Slave. Written by Himself\n",
            "5.000 (from 2 neigh)  B000NWUHR6  -  Catch-22\n",
            "5.000 (from 2 neigh)  1417627530  -  Year of Wonders (Turtleback School & Library Binding Edition)\n",
            "5.000 (from 2 neigh)  0460112872  -  Jane Eyre (Everyman's Classics)\n",
            "5.000 (from 2 neigh)  0395051150  -  Emma (Riverside Editions)\n",
            "5.000 (from 2 neigh)  B000Q032UY  -  The Hobbit or There and Back Again\n",
            "5.000 (from 2 neigh)  0435126024  -  Jane Eyre (New Windmill)\n",
            "5.000 (from 2 neigh)  B000P91JYW  -  Jane Eyre\n",
            "5.000 (from 2 neigh)  0140860428  -  Jane Eyre (Penguin Classics)\n",
            "5.000 (from 2 neigh)  B000H7EO2G  -  The Lord of the Rings Trilogy 3 Volumes\n",
            "5.000 (from 2 neigh)  B000C1X8JC  -  Pride and Prejudice\n",
            "5.000 (from 2 neigh)  0451513967  -  Pride and Prejudice\n",
            "5.000 (from 2 neigh)  0786135034  -  Pride and Prejudice\n",
            "5.000 (from 2 neigh)  B000IZ76B8  -  Gone with the Wind\n",
            "5.000 (from 2 neigh)  9562910334  -  1984\n",
            "5.000 (from 2 neigh)  B000NPEWHE  -  Harry Potter and the Chamber of Secrets\n",
            "5.000 (from 2 neigh)  B000K7WNQW  -  To Kill a Mockingbird\n",
            "5.000 (from 2 neigh)  0762405651  -  Little Women (Courage giant classics)\n",
            "5.000 (from 2 neigh)  B000BHA3PY  -  With No One As Witness (Thomas Lynley and Barbara Havers Novels)\n",
            "5.000 (from 2 neigh)  0606335463  -  The Full Cupboard of Life (The No. 1 Ladies' Detective Agency)\n",
            "5.000 (from 2 neigh)  8188280046  -  Pride & Prejudice (Classic Library)\n",
            "5.000 (from 2 neigh)  B0000CO4JZ  -  The Great Gatsby\n",
            "5.000 (from 2 neigh)  9562911306  -  Pride and Prejudice\n",
            "5.000 (from 2 neigh)  0563389524  -  Emma (Radio Collection)\n",
            "5.000 (from 2 neigh)  0333580443  -  Sense and Sensibility\n",
            "5.000 (from 2 neigh)  B00086U8GW  -  The sun also rises (The Modern library of the world's best books)\n",
            "5.000 (from 2 neigh)  B0006DXUU8  -  A Christmas carol: In prose\n",
            "5.000 (from 2 neigh)  9626341823  -  A Christmas Carol (Classic Fiction)\n",
            "5.000 (from 2 neigh)  0721417299  -  Christmas Carol (Ladybird Classics)\n",
            "5.000 (from 2 neigh)  0743477375  -  A Christmas Carol (Enriched Classics (Pocket))\n",
            "5.000 (from 2 neigh)  B000056MLJ  -  A Christmas Carol [One Voice Recordings Edition]\n",
            "5.000 (from 2 neigh)  0742623157  -  A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens)\n",
            "5.000 (from 2 neigh)  0904724719  -  Alice in Wonderland (Tell tales)\n",
            "5.000 (from 2 neigh)  140505347X  -  Alice's Adventures in Wonderland\n",
            "5.000 (from 2 neigh)  B00088BMEM  -  A tale of two cities\n",
            "5.000 (from 2 neigh)  0340283947  -  Alice in Wonderland\n",
            "5.000 (from 2 neigh)  B00005WLVX  -  Persuasion\n",
            "5.000 (from 2 neigh)  B000K0BJX2  -  \"Alice\"\"s Adventures in Wonderland\"\n",
            "5.000 (from 2 neigh)  B0006AQ4LI  -  Wuthering Heights\n",
            "5.000 (from 2 neigh)  068199570X  -  Wuthering Heights\n",
            "5.000 (from 2 neigh)  0606015825  -  Wuthering Heights\n",
            "5.000 (from 2 neigh)  B0006BV6RY  -  Wuthering Heights (College classics in English)\n",
            "5.000 (from 2 neigh)  0451521196  -  Wuthering Heights (Signet classics)\n",
            "5.000 (from 2 neigh)  0141804459  -  Pride & Prejudice (Penguin Classics)\n",
            "5.000 (from 2 neigh)  B000GROP62  -  Nineteen Eighty-four\n",
            "5.000 (from 2 neigh)  B000PRXGLS  -  The Adventures of Sherlock Holmes: Sherlock Holmes Mysteries: Authorized Edition\n",
            "5.000 (from 2 neigh)  B00009ANY1  -  1st to Die: A Novel\n",
            "4.667 (from 3 neigh)  B000QB9ZYA  -  Innocent\n",
            "4.667 (from 3 neigh)  B000GRR2GW  -  Blue Dahlia\n",
            "4.633 (from 3 neigh)  1593556195  -  Red Lily (In the Garden Series)\n",
            "4.618 (from 3 neigh)  1585476331  -  Superstition\n",
            "4.618 (from 3 neigh)  B000GRN0AE  -  Inner Harbor\n",
            "4.613 (from 3 neigh)  1590869060  -  Key of Valor (Key Trilogy)\n",
            "4.613 (from 3 neigh)  B00021GLU0  -  Full House\n",
            "4.577 (from 3 neigh)  1593556179  -  Black Rose (In the Garden Series)\n",
            "4.504 (from 2 neigh)  B000GLI9HY  -  Shutter Island\n",
            "4.500 (from 2 neigh)  0613706633  -  Middlemarch (Turtleback School & Library Binding Edition) (Penguin Classics)\n",
            "4.500 (from 2 neigh)  0515136379  -  Key of Knowledge\n",
            "4.500 (from 2 neigh)  1590869044  -  Key of Knowledge (Key Trilogy)\n",
            "4.500 (from 2 neigh)  1593356439  -  Key of Valor (Key Trilogy)\n",
            "4.500 (from 2 neigh)  0754095665  -  Key of Light (Key Trilogy)\n",
            "4.500 (from 2 neigh)  0758203594  -  Wilde Thing\n",
            "4.500 (from 2 neigh)  B000MV8HPC  -  All Night Long\n",
            "4.500 (from 2 neigh)  0399152806  -  Superstition\n",
            "4.500 (from 2 neigh)  0758208472  -  The Pregnancy Test\n",
            "4.500 (from 2 neigh)  B000NWQE2I  -  Carnal Innocence\n",
            "4.500 (from 2 neigh)  B000NU91AM  -  Full House (SIGNED)\n",
            "4.500 (from 2 neigh)  B00008HBR3  -  Full Tilt\n",
            "4.500 (from 2 neigh)  078625033X  -  Light in Shadow: A Whispering Springs Novel\n",
            "4.500 (from 2 neigh)  0375434658  -  Demon Rumm (Random House Large Print)\n",
            "4.474 (from 2 neigh)  B000OIZV66  -  Just One Look\n",
            "4.421 (from 2 neigh)  1593556160  -  Black Rose (In the Garden Series)\n",
            "4.419 (from 2 neigh)  1423305574  -  Vanished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_recommendation(user_id, target_item, top_m=3):\n",
        "    history = broadcast_history.value.get(user_id, [])\n",
        "    mu = bum.value.get(user_id, 4.0)\n",
        "    history_map = dict(history)\n",
        "\n",
        "    reasons = []\n",
        "    for j, sim_w, shrink, cnt in broadcast_neighbours.value.get(target_item, []):\n",
        "        if j in history_map:\n",
        "            contrib = sim_w * (history_map[j] - mu)\n",
        "            reasons.append((j, sim_w, shrink, cnt, history_map[j], contrib))\n",
        "\n",
        "    reasons.sort(key=lambda x: abs(x[5]), reverse=True)  # contrib is now x[5]\n",
        "    return reasons[:top_m]\n",
        "\n",
        "\n",
        "USER = \"A3M174IC0VXOS2\"\n",
        "recommendations = recommend_for_user_centered(USER, 10)\n",
        "\n",
        "for bid, prediction, c in recommendations:\n",
        "    print(f\"\\n{prediction:.3f} (from {c} neigh)  {book_titles.get(bid, bid)}\")\n",
        "    for j, sim_w, shrink, cnt, rj, contrib in explain_recommendation(USER, bid, top_m=3):\n",
        "        print(\n",
        "            f\"  because: {book_titles.get(j, j)} | \"\n",
        "            f\"sim'={sim_w:.3f} (shrink={shrink:.3f}, common={cnt}), your_rating={rj:.1f}, contrib={contrib:+.3f}\"\n",
        "        )\n"
      ],
      "metadata": {
        "id": "3Lqj0fAU-hY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4c619b-df14-49eb-feeb-e9b12e3905b4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5.000 (from 4 neigh)  Wuthering Heights (Signet classics)\n",
            "  because: Wuthering Heights | sim'=0.703 (shrink=0.714, common=25), your_rating=5.0, contrib=+0.178\n",
            "  because: Wuthering Heights (Riverside editions) | sim'=0.663 (shrink=0.667, common=20), your_rating=5.0, contrib=+0.167\n",
            "\n",
            "5.000 (from 4 neigh)  Pride & Prejudice (New Windmill)\n",
            "  because: Jane Eyre (Simple English) | sim'=0.286 (shrink=0.286, common=4), your_rating=5.0, contrib=+0.072\n",
            "  because: Jane Eyre (Large Print) | sim'=0.285 (shrink=0.286, common=4), your_rating=5.0, contrib=+0.072\n",
            "\n",
            "5.000 (from 4 neigh)  Wuthering Heights (Penguin Audiobooks)\n",
            "  because: Wuthering Heights | sim'=0.724 (shrink=0.730, common=27), your_rating=5.0, contrib=+0.183\n",
            "  because: Wuthering Heights (Riverside editions) | sim'=0.683 (shrink=0.688, common=22), your_rating=5.0, contrib=+0.173\n",
            "  because: Jane Eyre (Simple English) | sim'=0.374 (shrink=0.375, common=6), your_rating=5.0, contrib=+0.094\n",
            "\n",
            "5.000 (from 4 neigh)  Wuthering Heights\n",
            "  because: Wuthering Heights | sim'=0.707 (shrink=0.714, common=25), your_rating=5.0, contrib=+0.179\n",
            "  because: Wuthering Heights (Riverside editions) | sim'=0.673 (shrink=0.677, common=21), your_rating=5.0, contrib=+0.170\n",
            "  because: Jane Eyre (Simple English) | sim'=0.205 (shrink=0.231, common=3), your_rating=5.0, contrib=+0.052\n",
            "\n",
            "5.000 (from 3 neigh)  Jane Eyre / Wuthering Heights\n",
            "  because: Wuthering Heights | sim'=0.600 (shrink=0.600, common=15), your_rating=5.0, contrib=+0.152\n",
            "  because: Wuthering Heights (Riverside editions) | sim'=0.474 (shrink=0.474, common=9), your_rating=5.0, contrib=+0.120\n",
            "  because: Jane Eyre (Large Print) | sim'=0.167 (shrink=0.167, common=2), your_rating=5.0, contrib=+0.042\n",
            "\n",
            "5.000 (from 3 neigh)  Pride and Prejudice\n",
            "  because: Jane Eyre (Large Print) | sim'=0.412 (shrink=0.412, common=7), your_rating=5.0, contrib=+0.104\n",
            "\n",
            "5.000 (from 3 neigh)  Wuthering Heights (The Franklin Library)\n",
            "  because: Wuthering Heights (Riverside editions) | sim'=0.583 (shrink=0.583, common=14), your_rating=5.0, contrib=+0.147\n",
            "  because: Wuthering Heights | sim'=0.565 (shrink=0.565, common=13), your_rating=5.0, contrib=+0.143\n",
            "  because: Jane Eyre (Large Print) | sim'=0.230 (shrink=0.231, common=3), your_rating=5.0, contrib=+0.058\n",
            "\n",
            "5.000 (from 3 neigh)  The great Gatsby (Leading English literature library)\n",
            "\n",
            "5.000 (from 3 neigh)  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "  because: Jane Eyre (Large Print) | sim'=0.730 (shrink=0.730, common=27), your_rating=5.0, contrib=+0.184\n",
            "  because: Jane Eyre (Simple English) | sim'=0.643 (shrink=0.643, common=18), your_rating=5.0, contrib=+0.162\n",
            "  because: Wuthering Heights | sim'=0.282 (shrink=0.286, common=4), your_rating=5.0, contrib=+0.071\n",
            "\n",
            "5.000 (from 3 neigh)  Jane Eyre (Signet classics)\n",
            "  because: Jane Eyre (Large Print) | sim'=0.630 (shrink=0.630, common=17), your_rating=5.0, contrib=+0.159\n",
            "  because: Jane Eyre (Simple English) | sim'=0.545 (shrink=0.545, common=12), your_rating=5.0, contrib=+0.138\n",
            "  because: Wuthering Heights | sim'=0.227 (shrink=0.231, common=3), your_rating=5.0, contrib=+0.057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "train_df.groupBy(\"rating\").count().orderBy(\"rating\").show()\n"
      ],
      "metadata": {
        "id": "ZFa5aZrHFas5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd52910-3f41-47b4-ef5a-2bfc1296b8a9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|rating|count|\n",
            "+------+-----+\n",
            "|   1.0| 2248|\n",
            "|   2.0| 3007|\n",
            "|   3.0| 7477|\n",
            "|   4.0|17347|\n",
            "|   5.0|38228|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USER = \"A3M174IC0VXOS2\"\n",
        "print(\"user mean:\", bum.value.get(USER))\n"
      ],
      "metadata": {
        "id": "DYXPiU6PF0fq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a251f0-bbed-4202-d470-05294800617d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user mean: 4.747252747252747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_user_ranked(user_id, N=10, min_contrib=2, support_bonus=0.02):\n",
        "    hist = broadcast_history.value.get(user_id, [])\n",
        "    if not hist:\n",
        "        return []\n",
        "\n",
        "    mu = bum.value.get(user_id, 4.0)\n",
        "    seen = set(i for i, _ in hist)\n",
        "    hist_map = dict(hist)\n",
        "\n",
        "    scores = {}  # item -> (num, den, contrib)\n",
        "    for i, r_ui in hist:\n",
        "        for j, sim_w,  shrink, count in broadcast_neighbours.value.get(i, []):\n",
        "            if j in seen:\n",
        "                continue\n",
        "            num, den, c = scores.get(j, (0.0, 0.0, 0))\n",
        "            num += sim_w * (hist_map[i] - mu)\n",
        "            den += abs(sim_w)\n",
        "            c += 1\n",
        "            scores[j] = (num, den, c)\n",
        "\n",
        "    out = []\n",
        "    for j, (num, den, c) in scores.items():\n",
        "        if den > 1e-9 and c >= min_contrib:\n",
        "            pred = mu + num / den\n",
        "            pred = max(1.0, min(5.0, pred))\n",
        "            rank_score = pred + support_bonus * c   # tie-break\n",
        "            out.append((j, pred, c, rank_score))\n",
        "\n",
        "    out.sort(key=lambda x: x[3], reverse=True)\n",
        "    return out[:N]\n"
      ],
      "metadata": {
        "id": "yKh6paD6F3P7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER = \"A3M174IC0VXOS2\"\n",
        "recommendations = recommend_for_user_ranked(USER, N=15)\n",
        "\n",
        "for bid, prediction, c, score in recommendations:\n",
        "    print(f\"score={score:.3f} pred={prediction:.3f} (c={c})  {book_titles.get(bid, bid)}\")\n"
      ],
      "metadata": {
        "id": "Iq8quKvYIeyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6eac847-066e-4fa2-b878-949b42b2f864"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score=5.080 pred=5.000 (c=4)  Wuthering Heights (Signet classics)\n",
            "score=5.080 pred=5.000 (c=4)  Pride & Prejudice (New Windmill)\n",
            "score=5.080 pred=5.000 (c=4)  Wuthering Heights (Penguin Audiobooks)\n",
            "score=5.080 pred=5.000 (c=4)  Wuthering Heights\n",
            "score=5.060 pred=5.000 (c=3)  Jane Eyre / Wuthering Heights\n",
            "score=5.060 pred=5.000 (c=3)  Pride and Prejudice\n",
            "score=5.060 pred=5.000 (c=3)  Wuthering Heights (The Franklin Library)\n",
            "score=5.060 pred=5.000 (c=3)  The great Gatsby (Leading English literature library)\n",
            "score=5.060 pred=5.000 (c=3)  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "score=5.060 pred=5.000 (c=3)  Jane Eyre (Signet classics)\n",
            "score=5.060 pred=5.000 (c=3)  Jane Eyre\n",
            "score=5.060 pred=5.000 (c=3)  Wuthering Heights (New Windmill)\n",
            "score=5.060 pred=5.000 (c=3)  Wuthering Heights\n",
            "score=5.060 pred=5.000 (c=3)  Wuthering Heights\n",
            "score=5.060 pred=5.000 (c=3)  Pride and Prejudice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TopN evaluation"
      ],
      "metadata": {
        "id": "1MHK9K8o2H98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build per user train items\n",
        "\n",
        "# train items per user\n",
        "train_user_items_df = (\n",
        "    train_df.select(\"user_id\", \"book_id\")\n",
        "            .dropDuplicates()\n",
        "            .groupBy(\"user_id\")\n",
        "            .agg(functions.collect_set(\"book_id\").alias(\"train_items\"))\n",
        ")\n",
        "\n",
        "# test positives per user\n",
        "test_user_items_df = (\n",
        "    test_df.select(\"user_id\", \"book_id\")\n",
        "           .dropDuplicates()\n",
        "           .groupBy(\"user_id\")\n",
        "           .agg(functions.collect_set(\"book_id\").alias(\"test_items\"))\n",
        ")\n",
        "\n",
        "# join and filter users\n",
        "evaluated_users_df = (\n",
        "    train_user_items_df.join(test_user_items_df, on=\"user_id\", how=\"inner\")\n",
        "    .withColumn(\"n_train\", functions.size(\"train_items\"))\n",
        "    .withColumn(\"n_test\", functions.size(\"test_items\"))\n",
        "    .filter((functions.col(\"n_train\") >= MIN_TRAIN_ITEMS) & (functions.col(\"n_test\") >= MIN_TEST_POS))\n",
        ")\n",
        "\n",
        "print(\"Eligible evaluated users:\", evaluated_users_df.count())\n",
        "\n",
        "# sample users for speed\n",
        "evaluated_users_sample = evaluated_users_df.limit(MAX_USERS_EVAL).collect()\n",
        "print(\"Evaluating on users:\", len(evaluated_users_sample))\n"
      ],
      "metadata": {
        "id": "WMRPxzuqIhIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcdde1d-ccd4-4a47-db12-09932abcc9ff"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eligible evaluated users: 6351\n",
            "Evaluating on users: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation function that excludes seen items\n",
        "def recommend_topk_from_train_items(train_items, k=K_EVAL):\n",
        "    # train_items: list of item_ids the user has in train\n",
        "    seen = set(train_items)\n",
        "    scores = {}  # item -> score\n",
        "\n",
        "    # Spread scores from each seen item to its neighbors\n",
        "    for i in seen:\n",
        "        for j, sim_w, shrink, count in broadcast_neighbours.value.get(i, []):\n",
        "            if j in seen:\n",
        "                continue\n",
        "            scores[j] = scores.get(j, 0.0) + sim_w\n",
        "\n",
        "    # Top-k by score\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [item for item, s in ranked[:k]]\n"
      ],
      "metadata": {
        "id": "_g8W9T8w2G9c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics: precision, recall etc\n",
        "\n",
        "import math\n",
        "\n",
        "# Normalized Discounted Cumulative Gain\n",
        "def ndcg_at_k(recommended, positives, k):\n",
        "    # binary relevance: 1 if in positives\n",
        "    dcg = 0.0\n",
        "    for idx, item in enumerate(recommended[:k], start=1):\n",
        "        if item in positives:\n",
        "            dcg += 1.0 / math.log2(idx + 1)\n",
        "\n",
        "    # ideal DCG: all positives ranked first\n",
        "    ideal_hits = min(len(positives), k)\n",
        "    idcg = sum(1.0 / math.log2(i + 1) for i in range(1, ideal_hits + 1))\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "hits = 0\n",
        "sum_prec = 0.0\n",
        "sum_rec = 0.0\n",
        "sum_ndcg = 0.0\n",
        "n_users = 0\n",
        "\n",
        "for row in evaluated_users_sample:\n",
        "    user = row[\"user_id\"]\n",
        "    train_items = row[\"train_items\"]\n",
        "    test_items = set(row[\"test_items\"])\n",
        "\n",
        "    recommendations = recommend_topk_from_train_items(train_items, k=K_EVAL)\n",
        "    if not recommendations:\n",
        "        continue\n",
        "\n",
        "    recommendations_set = set(recommendations)\n",
        "    n_hit = len(recommendations_set.intersection(test_items))\n",
        "\n",
        "    # metrics\n",
        "    hit_rate = 1 if n_hit > 0 else 0\n",
        "    precision = n_hit / K_EVAL\n",
        "    recall = n_hit / len(test_items)\n",
        "\n",
        "    hits += hit_rate\n",
        "    sum_prec += precision\n",
        "    sum_rec += recall\n",
        "    sum_ndcg += ndcg_at_k(recommendations, test_items, K_EVAL)\n",
        "    n_users += 1\n",
        "\n",
        "print(\"Users evaluated:\", n_users)\n",
        "print(f\"HitRate@{K_EVAL}: {hits / n_users:.4f}\")\n",
        "print(f\"Precision@{K_EVAL}: {sum_prec / n_users:.4f}\")\n",
        "print(f\"Recall@{K_EVAL}: {sum_rec / n_users:.4f}\")\n",
        "print(f\"NDCG@{K_EVAL}: {sum_ndcg / n_users:.4f}\")\n"
      ],
      "metadata": {
        "id": "igN2xXUc3xDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf478a06-2624-4021-c6bc-d46958f50fc6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users evaluated: 1949\n",
            "HitRate@10: 0.4048\n",
            "Precision@10: 0.0494\n",
            "Recall@10: 0.2791\n",
            "NDCG@10: 0.1667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare to Popularity baseline"
      ],
      "metadata": {
        "id": "j1vbfOP14vvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POOL_LIMIT = 500\n",
        "popular_k = (\n",
        "    train_df.groupBy(\"book_id\")\n",
        "            .agg(functions.count(\"*\").alias(\"n\"), functions.avg(\"rating\").alias(\"average\"))\n",
        "            .orderBy(functions.col(\"n\").desc(), functions.col(\"average\").desc())\n",
        "            .limit(POOL_LIMIT)\n",
        "            .select(\"book_id\")\n",
        "            .rdd.map(lambda r: r[\"book_id\"])\n",
        "            .collect()\n",
        ")\n"
      ],
      "metadata": {
        "id": "pr_lry3Y4oIq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend func for popularity baseline\n",
        "\n",
        "def recommend_popularity(train_items, k=K_EVAL):\n",
        "    seen = set(train_items)\n",
        "    out = []\n",
        "    for item in popular_k:\n",
        "        if item not in seen:\n",
        "            out.append(item)\n",
        "        if len(out) >= k:\n",
        "            break\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "ba4ihU-T5Bms"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate populatity baseline\n",
        "\n",
        "hits = 0\n",
        "sum_precision = 0.0\n",
        "sum_recall = 0.0\n",
        "sum_ndcg = 0.0\n",
        "n_users = 0\n",
        "\n",
        "for row in evaluated_users_sample:\n",
        "    train_items = row[\"train_items\"]\n",
        "    test_items = set(row[\"test_items\"])\n",
        "\n",
        "    recommendations = recommend_popularity(train_items, k=K_EVAL)\n",
        "    if not recommendations:\n",
        "        continue\n",
        "\n",
        "    recommendations_set = set(recommendations)\n",
        "    n_hit = len(recommendations_set.intersection(test_items))\n",
        "\n",
        "    hits += 1 if n_hit > 0 else 0\n",
        "    sum_precision += n_hit / K_EVAL\n",
        "    sum_recall += n_hit / len(test_items)\n",
        "    sum_ndcg += ndcg_at_k(recommendations, test_items, K_EVAL)\n",
        "    n_users += 1\n",
        "\n",
        "print(\"Popularity baseline:\")\n",
        "print(\"Users evaluated:\", n_users)\n",
        "print(f\"HitRate@{K_EVAL}: {hits / n_users:.4f}\")\n",
        "print(f\"Precision@{K_EVAL}: {sum_precision / n_users:.4f}\")\n",
        "print(f\"Recall@{K_EVAL}: {sum_recall / n_users:.4f}\")\n",
        "print(f\"NDCG@{K_EVAL}: {sum_ndcg / n_users:.4f}\")\n"
      ],
      "metadata": {
        "id": "oMsKQAt45Rrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fb706a-92d7-487c-d017-25ebb098a44a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Popularity baseline:\n",
            "Users evaluated: 2000\n",
            "HitRate@10: 0.0440\n",
            "Precision@10: 0.0048\n",
            "Recall@10: 0.0264\n",
            "NDCG@10: 0.0135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def get_title_key(title: str, max_words: int = 5) -> str:\n",
        "    if not title:\n",
        "        return \"\"\n",
        "    title = title.lower()\n",
        "    title = re.sub(r\"\\(.*?\\)\", \" \", title) # remove (...) content\n",
        "    title = re.sub(r\"\\[.*?\\]\", \" \", title) # remove [...] content\n",
        "    title = title.replace(\"&\", \"and\")\n",
        "    title = re.sub(r\"[^a-z0-9 ]+\", \" \", title) # drop punctuation\n",
        "\n",
        "    TAIL_PATTERNS = [\n",
        "        r\"\\bin prose\\b\",\n",
        "        r\"\\ba novel\\b\",\n",
        "        r\"\\ba memoir\\b\",\n",
        "        r\"\\b(collected|complete) works\\b\",\n",
        "        r\"\\b(authorized|enriched|illustrated) edition\\b\",\n",
        "    ]\n",
        "\n",
        "    for pat in TAIL_PATTERNS:\n",
        "        title = re.sub(pat, \" \", title)\n",
        "    title = re.sub(r\"\\s+\", \" \", title).strip()\n",
        "\n",
        "    # drop common edition-ish suffix words\n",
        "    stop = {\n",
        "        \"unabridged\",\"abridged\",\"audio\",\"audiobook\",\"cassette\",\"cd\",\"edition\",\n",
        "        \"classics\",\"classic\",\"collected\",\"works\",\"library\",\"binding\",\"series\",\n",
        "        \"penguin\",\"signet\",\"everyman\",\"oxford\",\"illustrated\",\"volume\",\"vol\",\n",
        "        \"part\",\"story\",\"being\",\"ghost\",\n",
        "        \"a\",\"an\",\"the\",\"of\",\"and\",\"or\",\"to\",\"for\",\"in\",\"on\",\"by\",\"with\",\"from\",\"at\"\n",
        "    }\n",
        "    words = [word for word in title.split() if word not in stop]\n",
        "\n",
        "    # remove duplicate tokens while keeping order\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for word in words:\n",
        "        if word not in seen:\n",
        "            seen.add(word)\n",
        "            uniq.append(word)\n",
        "    words = uniq\n",
        "\n",
        "    return \" \".join(words[:max_words])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BxFfb0Bw5qUM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_articles(title_key: str) -> str:\n",
        "    # drop leading articles\n",
        "    for article in (\"a \", \"an \", \"the \"):\n",
        "        if title_key.startswith(article):\n",
        "            return title_key[len(article):]\n",
        "    return title_key\n"
      ],
      "metadata": {
        "id": "Cy7ay_8-tLtu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dedupe_recs(recommendations, book_titles, topn=10):\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for bid, pred, c in recommendations:\n",
        "        title = book_titles.get(bid, \"\")\n",
        "        key_title = normalize_articles(get_title_key(title, max_words=5))\n",
        "        if not key_title or key_title in seen:\n",
        "            continue\n",
        "        seen.add(key_title)\n",
        "        out.append((bid, pred, c, title))\n",
        "        if len(out) >= topn:\n",
        "            break\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "3UqjkeiGtPct"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = recommend_for_user_centered(USER, 100)\n",
        "pretty = dedupe_recs(raw, book_titles, topn=10)\n",
        "\n",
        "for bid, pred, c, title in pretty:\n",
        "    print(f\"{pred:.3f} (from {c} neigh)  {bid}  -  {title}\")\n"
      ],
      "metadata": {
        "id": "vWH5XD1vi5w1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7893a8f-7d06-4dfb-eae1-cfe93236868d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.000 (from 4 neigh)  0451519582  -  Wuthering Heights (Signet classics)\n",
            "5.000 (from 4 neigh)  0435126075  -  Pride & Prejudice (New Windmill)\n",
            "5.000 (from 3 neigh)  B000FFQ85G  -  Jane Eyre / Wuthering Heights\n",
            "5.000 (from 3 neigh)  B0007C10MS  -  The great Gatsby (Leading English literature library)\n",
            "5.000 (from 3 neigh)  0140351310  -  Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "5.000 (from 3 neigh)  0451518845  -  Jane Eyre (Signet classics)\n",
            "5.000 (from 3 neigh)  B000PMCF1A  -  The Catcher in the Rye [Audiobook] [Cd] [Unabridged] (Audio CD)\n",
            "5.000 (from 3 neigh)  B0000632ZL  -  The Summons\n",
            "5.000 (from 2 neigh)  B000NPAT6W  -  Narrative of the Life of Frederick Douglass, An American Slave. Written by Himself\n",
            "5.000 (from 2 neigh)  B000NWUHR6  -  Catch-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for bid, pred, c in raw[:30]:\n",
        "    title = book_titles.get(bid, \"\")\n",
        "    key_title = normalize_articles(get_title_key(title, max_words=5))\n",
        "    print(f\"{key_title:25s} | {title}\")\n"
      ],
      "metadata": {
        "id": "_Svi1Ho3tVvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf72fdfb-6574-4dee-dfc2-3dc6746a43af"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wuthering heights         | Wuthering Heights (Signet classics)\n",
            "pride prejudice           | Pride & Prejudice (New Windmill)\n",
            "wuthering heights         | Wuthering Heights (Penguin Audiobooks)\n",
            "wuthering heights         | Wuthering Heights\n",
            "jane eyre wuthering heights | Jane Eyre / Wuthering Heights\n",
            "pride prejudice           | Pride and Prejudice\n",
            "wuthering heights         | Wuthering Heights (The Franklin Library)\n",
            "great gatsby              | The great Gatsby (Leading English literature library)\n",
            "jane eyre complete        | Jane Eyre: Complete and Unabridged (Puffin Classics)\n",
            "jane eyre                 | Jane Eyre (Signet classics)\n",
            "jane eyre                 | Jane Eyre\n",
            "wuthering heights         | Wuthering Heights (New Windmill)\n",
            "wuthering heights         | Wuthering Heights\n",
            "wuthering heights         | Wuthering Heights\n",
            "pride prejudice           | Pride and Prejudice\n",
            "wuthering heights         | Wuthering Heights\n",
            "wuthering heights         | Wuthering Heights.\n",
            "wuthering heights         | Wuthering Heights\n",
            "wuthering heights         | Wuthering Heights\n",
            "catcher rye               | The Catcher in the Rye [Audiobook] [Cd] [Unabridged] (Audio CD)\n",
            "summons                   | The Summons\n",
            "narrative life frederick douglass american | Narrative of the Life of Frederick Douglass, An American Slave. Written by Himself\n",
            "catch 22                  | Catch-22\n",
            "year wonders              | Year of Wonders (Turtleback School & Library Binding Edition)\n",
            "jane eyre                 | Jane Eyre (Everyman's Classics)\n",
            "emma                      | Emma (Riverside Editions)\n",
            "hobbit there back again   | The Hobbit or There and Back Again\n",
            "jane eyre                 | Jane Eyre (New Windmill)\n",
            "jane eyre                 | Jane Eyre\n",
            "jane eyre                 | Jane Eyre (Penguin Classics)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\n",
        "    \"A Christmas carol: In prose\",\n",
        "    \"A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens)\",\n",
        "    \"Christmas Carol (Ladybird Classics)\",\n",
        "]\n",
        "for tt in titles:\n",
        "    print(get_title_key(tt), \"|\", tt)\n"
      ],
      "metadata": {
        "id": "YAgHBc3wl-Hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07cec21-ce33-4584-ae6a-94a3eaa57e6f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "christmas carol | A Christmas carol: In prose\n",
            "christmas carol | A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens)\n",
            "christmas carol | Christmas Carol (Ladybird Classics)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8bsh95-zD9Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}